{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "\n",
    "(â•¯Â°â–¡Â°)â•¯ï¸µâ—“\n",
    "\n",
    "You've been search far and wide, but you're still trying to understand the power that's inside. This time round though, you're armed with new weapons: supervised learning algorithms. Pokemons will have no more secrets after you analyse the pokedex!\n",
    "\n",
    "The data can be found under `pokedex/pokemons.csv`, and is the same as homeworks 1, 2, & 3. Run the cell below to get an overview of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amine/.local/share/virtualenvs/practical-data-scientist-umj5maBJ-python/lib/python3.9/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>625</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #                   Name Type 1  Type 2  Total  HP  Attack  Defense  \\\n",
       "0  1              Bulbasaur  Grass  Poison    318  45      49       49   \n",
       "1  2                Ivysaur  Grass  Poison    405  60      62       63   \n",
       "2  3               Venusaur  Grass  Poison    525  80      82       83   \n",
       "3  3  VenusaurMega Venusaur  Grass  Poison    625  80     100      123   \n",
       "4  4             Charmander   Fire     NaN    309  39      52       43   \n",
       "\n",
       "   Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0       65       65     45           1      False  \n",
       "1       80       80     60           1      False  \n",
       "2      100      100     80           1      False  \n",
       "3      122      120     80           1      False  \n",
       "4       60       50     65           1      False  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('pokedex/pokemons.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "We've learned that Pokemon masters never mix training and battles. Since we are building supervised learning models, we want to _split our data_ into train and test datasets. We are only running a single round of experiments with no hyperparameter optimisation, so we'll skip validation sets this time.\n",
    "\n",
    "ðŸ’ª **Task: Split the `df` DataFrame into training and test DataFrames.**\n",
    "- the split should be 80% training 20% test\n",
    "- use `random_state=0`\n",
    "- store your datasets into two variables called `train_df` and `test_df`. No need to save to disk!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "def test_split():\n",
    "    assert \"train_df\" in globals(), \"Can't find train_df, have you used the correct variable name for your train dataset?\"\n",
    "    assert \"test_df\" in globals(), \"Can't find train_df, have you used the correct variable name for your test dataset?\"\n",
    "    assert train_df[\"Total\"].sum() == 275746, \"Your dataset split doesn't look quite right. Did you use the correct random_state?\"\n",
    "    print('Success! ðŸŽ‰')\n",
    "\n",
    "test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just in case\n",
    "train_df.to_csv('pokedex/pokemons_train.csv', index=False)\n",
    "test_df.to_csv('pokedex/pokemons_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have split our dataset, we are ready to train. A crucial statistic in pokemon battles is `HP`. This is the amount of damage you have to inflict to your opponent to win the fight, so being able to _predict_ this amount would be an enormous advantage ðŸ‘Š.\n",
    "\n",
    "ðŸ’ª **Task: Train a linear regression model which predicts the label `HP`.**\n",
    "- train the model on your training dataset\n",
    "- use `Attack`, `Defense`, `Sp. Atk`, `Sp. Def`, and `Speed` as features\n",
    "- use `HP` as label\n",
    "- scale the features using standardization before you train the model\n",
    "- store your trained model in a variable called `reg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "def to_features(df, feature_list, label_list):\n",
    "    X = df[feature_list].values\n",
    "    y = df[label_list].values\n",
    "    return X, y\n",
    "\n",
    "feature_list = ['Attack','Defense','Sp. Atk','Sp. Def','Speed']\n",
    "label_list = 'HP'\n",
    "X_train, y_train = to_features(train_df, feature_list, label_list)\n",
    "\n",
    "#Standardization\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "#Training model\n",
    "reg = LinearRegression().fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def test_regression():\n",
    "    assert reg, \"Can't find reg, have you used the correct variable name for your model?\"\n",
    "    assert math.isclose(reg.coef_.sum(), 15.46275, rel_tol=1e-6), \"Your model parameters don't look quite right\"\n",
    "    print('Success! ðŸŽ‰')\n",
    "\n",
    "test_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ§  **Bonus Task: List and describe the main steps that happen during your linear regression model's _training_ , i.e inside of sklearn's `.fit()` method.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 1 : random init for `theta` parameter of the model\n",
    "- Step 2 : cost function estimation for the model J\n",
    "- Step 3 : derivative applied to the cost function d J / d theta\n",
    "- Step 4 : moving propotionaly to the negative of the result of Step 3 derivation -  (d J / d theta)\n",
    "- Step 5 : Go on Step 2 and reproduce until the cost function estimation is always on the same minimal value (limit?)  ==>   d J / d theta ~= 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ§  **Bonus Task: Explain the purpose of feature scaling, and why it's a good idea to use it here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main goal is to scale different features on different range on the same range while keeping the proportion. Some functions used on machine learning will not work properly whitout this normalization.\n",
    "In our case using regression it's a good idea to use it because we calculate derivative of cost function, so i think it could go wrong mathematicaly if every feature is not balanced proportionnaly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "You encounter an unknown pokemon, and it looks very strong. ðŸ™€ Use your `HP` regression model to see if you can take it on!\n",
    "\n",
    "ðŸ’ª **Task: Predict the `HP` of an unknown pokemon using your linear regression model.**\n",
    "- the stats of the unknown pokemon are found below\n",
    "- predict using your trained model, `reg`\n",
    "- store the prediction in a variable called `y_predict`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = 79\n",
    "defense = 109\n",
    "sp_atk = 73\n",
    "sp_def = 84\n",
    "speed = 68\n",
    "\n",
    "X_unknown_pokemon = np.asarray([attack,defense,sp_atk,sp_def,speed]).reshape(1, 5)\n",
    "X_scaled_unknown_pokemon = scaler.transform(X_unknown_pokemon)\n",
    "y_predict = reg.predict(X_scaled_unknown_pokemon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! ðŸŽ‰\n",
      "The unknown pokemon has predicted HP: 70.3\n"
     ]
    }
   ],
   "source": [
    "def test_predict_hp():\n",
    "    expected_prediction = 70.324\n",
    "    assert y_predict, f\"Can't find y_predict, have you used the correct variable name?\"\n",
    "    assert math.isclose(y_predict, expected_prediction, rel_tol=1e-4), f'The prediction should be {expected_prediction}, but your model predicted {y_predict}'\n",
    "    print('Success! ðŸŽ‰')\n",
    "    print(f\"The unknown pokemon has predicted HP: {y_predict.item():.1f}\")\n",
    "    return\n",
    "\n",
    "test_predict_hp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "Professor Oak told you about a rare breed of exceptionally powerful pokemon... the _legendary_ pokemon. A trainer who finds and captures a legendary pokemon is sure to become invicible!\n",
    "\n",
    "ðŸ’ª **Task: Train a logistic regression model which predicts if pokemons are `Legendary`.**\n",
    "- train the model on your training dataset\n",
    "- use `HP`, `Attack`, `Defense`, `Sp. Atk`, `Sp. Def`, and `Speed` as features\n",
    "- use `Legendary` as label\n",
    "- scale the features using standardization before you train the model\n",
    "- store your trained model in a variable called `clf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "feature_list = ['HP','Attack','Defense','Sp. Atk','Sp. Def','Speed']\n",
    "label_list = 'Legendary'\n",
    "X_train, y_train = to_features(train_df, feature_list, label_list)\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "# Learning model\n",
    "clf = LogisticRegression(random_state=0).fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "def test_classification():\n",
    "    assert clf, \"Can't find clf, have you used the correct variable name for your model?\"\n",
    "    assert math.isclose(clf.coef_.sum(), 5.71640, rel_tol=1e-5), \"Your model parameters don't look quite right\"\n",
    "    print('Success! ðŸŽ‰')\n",
    "    return\n",
    "\n",
    "test_classification()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ§  **Bonus Task: What are the differences between logistic regression and linear regression?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression aim to answer to a quantity prediction problem while Logistic regression aim to answer to a classification problem (predicting a label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Problem 5\n",
    "\n",
    "Finding legendary pokemons is no easy task, and we expect that we need a more _powerful_ model to accurately predict them.\n",
    "\n",
    "ðŸ’ª **Task: Train a logistic regression model with polynomial features and regularization which predicts if pokemons are Legendary.**\n",
    "- use `HP`, `Attack`, `Defense`, `Sp. Atk`, `Sp. Def`, and `Speed` as features\n",
    "- use `Legendary` as label\n",
    "- add polynomial features of degree 3\n",
    "- scale the features using standardization before you train the model\n",
    "- use ridge logistic regression to regularize your model\n",
    "- store your trained model in a variable called `clf`  \n",
    "Pro-tip: [RidgeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "feature_list = ['HP','Attack','Defense','Sp. Atk','Sp. Def','Speed']\n",
    "label_list = 'Legendary'\n",
    "X_train, y_train = to_features(train_df, feature_list, label_list)\n",
    "X_test, y_test = to_features(test_df, feature_list, label_list)\n",
    "\n",
    "# Polynomial features\n",
    "poly_degree = 3\n",
    "poly = PolynomialFeatures(poly_degree, include_bias=False)\n",
    "poly = poly.fit(X_train)\n",
    "X_poly = poly.transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_poly)\n",
    "X_train_scaled = scaler.transform(X_poly)\n",
    "X_test_scaled = scaler.transform(X_test_poly)\n",
    "\n",
    "# Learning model\n",
    "clf = RidgeClassifier(random_state=0).fit(X_train_scaled, y_train)\n",
    "clf_score = clf.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "def test_polynomial_regression():\n",
    "    assert clf, \"Can't find clf, have you used the correct variable name for your model?\"\n",
    "    assert math.isclose(clf.coef_.sum(), 0.340915, rel_tol=1e-5), \"Your model parameters don't look quite right\"\n",
    "    print('Success! ðŸŽ‰')\n",
    "    return\n",
    "\n",
    "test_polynomial_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ§  **Bonus Task: How do polynomial features make our model more powerful?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear models works well but have some limitations, polynomial features allows to our models to learn more complex hypotheses by adding more features to the learning algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ§  **Bonus Task: What is the purpose of regularization? Why is it a good idea to use it here?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization helps to solve the overfitting problem of our model. If we use classic logistic Regression we will need more max_iter to find a convergence and we will have a result that is overfitting our data.\n",
    "As refered to the RidgeClassifier docs : This classifier first converts the target values into {-1, 1} and then treats the problem as a regression task (multi-output regression in the multiclass case). Therefore it's more logic to use that for a task where we used polynomial features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’ª **Bonus Task: Train the exact same regularized logistic regression model with polynomial features, but this time, chain your preprocessors and your model into a [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=Pipeline(steps=[('polynomialfeatures',\n",
       "                                        PolynomialFeatures(include_bias=False)),\n",
       "                                       ('standardscaler', StandardScaler()),\n",
       "                                       ('ridgeclassifier',\n",
       "                                        RidgeClassifier(random_state=0))]),\n",
       "             param_grid={'polynomialfeatures__degree': [2, 3, 4]})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "feature_list = ['HP','Attack','Defense','Sp. Atk','Sp. Def','Speed']\n",
    "label_list = 'Legendary'\n",
    "X_train, y_train = to_features(train_df, feature_list, label_list)\n",
    "X_test, y_test = to_features(test_df, feature_list, label_list)\n",
    "\n",
    "# Composite estimator\n",
    "model = make_pipeline(PolynomialFeatures(include_bias=False),\n",
    "                     StandardScaler(),\n",
    "                     RidgeClassifier(random_state=0))\n",
    "params = {\n",
    "    'polynomialfeatures__degree' : [2,3,4]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(model, param_grid=params, cv=4)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Problem 5 parms : 'polynomialfeatures__degree': 3 with a score of 0.93125\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Problem 5 parms : 'polynomialfeatures__degree': {poly_degree} with a score of {clf_score}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Best params : {'polynomialfeatures__degree': 2} with a score of 0.925\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Best params : {grid.best_params_} with a score of {grid.score(X_test, y_test)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which means Problem 5 polynomial degree is overfitting ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6\n",
    "\n",
    "You are travelling across the land, when you spot a large rainbow bird in the sky. Maybe it's a legendary pokemon! Let's check with our freshly trained regularized polynomial classifier.\n",
    "\n",
    "ðŸ’ª **Task: Predict if the rainbow bird is a legendary pokemon using your classifier.**\n",
    "- the stats of the rainbow bird pokemon are found below\n",
    "- predict using your trained model, `clf`\n",
    "- store the prediction in a variable called `y_predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = 106\n",
    "attack = 130\n",
    "defense = 90\n",
    "sp_atk = 110\n",
    "sp_def = 154\n",
    "speed = 90\n",
    "\n",
    "X_unknown_pokemon = np.asarray([hp,attack,defense,sp_atk,sp_def,speed]).reshape(1, 6)\n",
    "X_poly_pokemon = poly.transform(X_unknown_pokemon)\n",
    "X_scaled_pokemon = scaler.transform(X_poly_pokemon)\n",
    "y_predict = clf.predict(X_scaled_pokemon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! ðŸŽ‰\n",
      "The rainbow bird is predicted to be a legendary pokemon!\n"
     ]
    }
   ],
   "source": [
    "def test_predict_legendary():\n",
    "    assert y_predict == True, f'The prediction should be {True}, but your model predicted {y_predict}'\n",
    "    print('Success! ðŸŽ‰')\n",
    "    print(\"The rainbow bird is predicted to be a legendary pokemon!\")\n",
    "    \n",
    "test_predict_legendary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7\n",
    "\n",
    "This legendary pokemon classifier is neat, and the Pokedex scientists are interested in including it in their next update. However, they want to make sure that it is accurate enough. \n",
    "\n",
    "\n",
    "ðŸ’ª **Task: Evaluate the accuracy of your legendary Pokemon classifier.**\n",
    "- evaluate your model on your test dataset\n",
    "- store the prediction in a variable called `accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = clf.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! ðŸŽ‰\n",
      "You can predict legendary pokemons with an accuracy of 93.1%!\n"
     ]
    }
   ],
   "source": [
    "def test_evaluation():\n",
    "    assert math.isclose(accuracy, 0.93125, rel_tol=1e-5), \"Your accuracy doesn't look quite right\"\n",
    "    print('Success! ðŸŽ‰')\n",
    "    print(f\"You can predict legendary pokemons with an accuracy of {accuracy*100:.1f}%!\")\n",
    "    \n",
    "test_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ§  **Bonus Task: What is the definition of the accuracy metric?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's the number of correct predictions divided by the total number of predictions multiplied by 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
